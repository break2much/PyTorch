{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52319</th>\n",
       "      <td>110638</td>\n",
       "      <td>Чот вторую часть пока догнать не могу.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9581</th>\n",
       "      <td>99687</td>\n",
       "      <td>За третье место 250 австралийских долларов. Ну...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72363</th>\n",
       "      <td>59838</td>\n",
       "      <td>на 3к строк кроме как поиграться с word2vec за...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58152</th>\n",
       "      <td>36932</td>\n",
       "      <td>Д 37.СТРОЙН.ПОЗН с Парнем до 40.С/О ДНЕПРОДЗ.А...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73412</th>\n",
       "      <td>40192</td>\n",
       "      <td>Мне сказали, мало ритейла с мл</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  label\n",
       "52319  110638             Чот вторую часть пока догнать не могу.      0\n",
       "9581    99687  За третье место 250 австралийских долларов. Ну...      2\n",
       "72363   59838  на 3к строк кроме как поиграться с word2vec за...      2\n",
       "58152   36932  Д 37.СТРОЙН.ПОЗН с Парнем до 40.С/О ДНЕПРОДЗ.А...      1\n",
       "73412   40192                     Мне сказали, мало ритейла с мл      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle = True, random_state = 666)\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, texts):\n",
    "        self.id2token = ['<bos>', '<eos>', '<unk>', '<pad>', '<mask>']\n",
    "        self.id2token += list(set([char for text in texts for char in text]))\n",
    "        self.token2id = {char: i for i, char in enumerate(self.id2token)}\n",
    "        self.UNK = self.token2id['<unk>']\n",
    "        self.EOS = self.token2id['<eos>']\n",
    "        self.BOS = self.token2id['<bos>']\n",
    "        self.PAD = self.token2id['<pad>']\n",
    "        self.MASK = self.token2id['<mask>']\n",
    "        \n",
    "    def text2id(self, text: str) -> list:\n",
    "        return [self.token2id.get(char, self.UNK) for char in text] \n",
    "        \n",
    "    def id2text(self,ids:list)->str:\n",
    "        return \"\".join([self.id2token[i] for i in ids]) #все строки сложили\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[209, 121, 341, 103, 582, 78, 244, 413, 21, 413, 244, 381, 582, 340, 21]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(train_df['text'].tolist())\n",
    "text = 'привет как дела'\n",
    "ids = vocab.text2id(text)\n",
    "new_text = vocab.id2text(ids)\n",
    "print(ids)\n",
    "assert text == new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, vocab ):\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # торч ожидает что возвращается тупль\n",
    "        row = self.df.iloc[idx] #забираем всю строку из dataframe\n",
    "        text, label = row['text'], row['label']\n",
    "        ids = self.vocab.text2id(text)\n",
    "        ids = torch.tensor(ids)\n",
    "        return ids, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 57,  21, 346, 244, 340, 199, 262, 340, 199, 244,  78, 442, 413,  21,\n",
       "         244,  78, 582, 262, 346, 529, 341,  57, 103, 582,  87, 341, 244,  78,\n",
       "         442, 413,  21, 244,  78, 582, 262, 346, 244, 341,  57, 103, 582,  87,\n",
       "         341, 244, 363,  78, 442, 244, 346, 244,  87, 582, 244, 209, 442,  87,\n",
       "         341, 301,  21, 340,  21, 244,  73,  78, 442, 460, 442, 244, 121,  21,\n",
       "          87, 189, 132, 582, 529,  78, 103, 442, 346, 244, 413, 341, 305, 199,\n",
       "         529, 340, 199, 262, 340, 199, 529, 244, 449, 381, 301, 341,  87, 244,\n",
       "         209, 121, 341, 381, 582, 121, 166, 341]),\n",
       " 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = MyDataset(train_df, vocab)\n",
    "print(len(ds))\n",
    "ds[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "PAD = vocab.PAD\n",
    "def collate_fn(batch): #на вход мписок туплей ids, label\n",
    "    lens =torch.tensor([len(x) for x, y in batch]) #длины всех последовательностей\n",
    "    batch_labels = torch.tensor([y for x, y in batch])\n",
    "    seqs = [x for x, y in batch]\n",
    "    batch_ids = pad_sequence(seqs, batch_first = True, padding_value = PAD) #падит по длине(делае м одной длины)\n",
    "    return {'x':batch_ids, 'lens': lens}, batch_labels\n",
    "#вернем тупль из тензеров/словарей 1 элемент - x  2- y(то что в loss)\n",
    "# в нашем случае вернем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[126,  21, 121,  ...,   3,   3,   3],\n",
       "        [ 78, 442, 244,  ...,   3,   3,   3],\n",
       "        [126, 442, 381,  ...,  78, 189, 307],\n",
       "        ...,\n",
       "        [294, 244, 121,  ...,   3,   3,   3],\n",
       "        [327, 529, 361,  ...,   3,   3,   3],\n",
       "        [529, 581, 145,  ...,   3,   3,   3]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(ds, batch_size = 8, shuffle = True, collate_fn = collate_fn)\n",
    "batch = next(iter(dl))\n",
    "batch[0]['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предсказываем класс текста\n",
    "# BERT: Transf Enc\n",
    "# GPT: Transf Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTransformer(nn.Module):\n",
    "    def __init__(self, d, vocab_size,  n_head, d_hid, n_blocks, n_classes):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, d, padding_idx = PAD)#по id получаем эмбединги\n",
    "        # TODO pos embedings не смертельная необходимость\n",
    "        Layers = [TransformerEncoderBlock(d, n_head, d_hid) for i in range(n_blocks)]\n",
    "        self.enc = nn.Sequential(*Layers)# n трансформерных блоков\n",
    "        self.clf = nn.Linear(d, n_classes)    \n",
    "            \n",
    "    def forward(self, x_batch): \n",
    "        # TODO padding\n",
    "        out = self.emb(x_batch['x'])\n",
    "        out = self.enc(out)\n",
    "        out = self.clf(out[:, 0, :])\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "attachments": {
    "1.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1.png](attachment:1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def pos_emb(max_len, d):\n",
    "    pe = torch.zeros(max_len, d)\n",
    "    position = torch.arange(0, max_len).unsqueeze(1)\n",
    "    div =torch.exp(torch.arange(0, d, 2)) *-(math.log(1000.0) / d)\n",
    "    pe[:, 0::2] = torch.sin(position * div)\n",
    "    pe[:, 1::2] = torch.cos(position * div)\n",
    "    return pe\n",
    "    \n",
    "class MLMTransformer(nn.Module):\n",
    "    def __init__(self, d, vocab_size,  n_head, d_hid, n_blocks):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, d, padding_idx = PAD)#по id получаем эмбединги\n",
    "        # TODO pos embedings не смертельная необходимость\n",
    "        Layers = [TransformerEncoderBlock(d, n_head, d_hid) for i in range(n_blocks)]\n",
    "        self.enc = nn.Sequential(*Layers)# n трансформерных блоков\n",
    "        self.clf = nn.Linear(d, vocab_size)    \n",
    "            \n",
    "    def forward(self, x_batch):\n",
    "        # TODO padding\n",
    "        out = self.emb(x_batch)\n",
    "        out = out + pos_emb(out.shape[1], out.shape[2])\n",
    "        out = self.enc(out)\n",
    "        out = self.clf(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self,d, n_head, d_hid):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d) #ADD&NORM\n",
    "        self.ln2 = nn.LayerNorm(d)  #ADD&NORM\n",
    "        self.mha = MultiHeadAttention(d, n_head)\n",
    "        self.ffd = nn.Sequential(\n",
    "            nn.Linear(d, d_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_hid, d)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.mha(x)\n",
    "        x = self.ln1(x + residual)\n",
    "        residual = x\n",
    "        x = self.ffd(x)\n",
    "        x = self.ln2(x + residual)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d, n_head):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(n_head):\n",
    "            self.heads.append(OneHeadAttention(d, n_head))\n",
    "        self.out_proj = nn.Linear(n_head*d, d, bias = True)\n",
    "    def forward(self, x):\n",
    "        out_heads = []\n",
    "        for head in self.heads:\n",
    "            out_heads.append(head(x))\n",
    "        out = torch.cat(out_heads, dim = -1)\n",
    "        out = self.out_proj(out)\n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHeadAttention(nn.Module):\n",
    "        def __init__(self, d, n_head):\n",
    "            super().__init__()\n",
    "            self.q = nn.Linear(d, d, bias = False)\n",
    "            self.k = nn.Linear(d, d, bias = False)\n",
    "            self.v = nn.Linear(d, d, bias = False)\n",
    "            self.d = d\n",
    "        def forward(self, x):\n",
    "            q = self.q(x)\n",
    "            k = self.k(x)\n",
    "            v = self.v(x)\n",
    "            out = torch.matmul(q.transpose(1,2), k)/ self.d **0.5 #.transpose(1,2) меняем размерности местами\n",
    "            out = F.softmax(out, dim = -1)\n",
    "            out = out @ v.transpose(1, 2)\n",
    "            return out.transpose(1, 2)       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassificationTransformer(vocab_size = len(vocab),\n",
    "                                  d = 32, n_head = 4, d_hid = 64, \n",
    "                                  n_blocks = 2, n_classes = 3\n",
    "                                 )\n",
    "\n",
    "out = model(batch[0])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def test(model, test_df):\n",
    "    ds = MyDataset(test_df, vocab)\n",
    "    dl = DataLoader(ds, batch_size =8, shuffle = False, collate_fn = collate_fn)\n",
    "    y_preds = []\n",
    "    for x_batch, y_batch in dl:\n",
    "        \n",
    "        y_pred = model(x_batch)\n",
    "        y_preds.append(y_pred) # список тензеров 8*3\n",
    "    \n",
    "    y_preds = torch.cat(y_preds, dim = 0)\n",
    "    torch.argmax(y_preds, dim =-1).numpy() #нужно взять номер максимального\n",
    "    return f1_score(test_df['label'], y_preds, average='micro')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "num_epoch = 10\n",
    "\n",
    "dl = DataLoader(ds, batch_size = 8, shuffle = True, collate_fn = collate_fn)\n",
    "model = ClassificationTransformer(vocab_size = len(vocab),\n",
    "                                  d = 32, n_head = 4, d_hid = 64, \n",
    "                                  n_blocks = 2, n_classes = 3\n",
    "                                 )\n",
    "opt = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    for num_step, (x_batch, y_batch) in tqdm(enumerate(dl)):\n",
    "        opt.zero_grad()\n",
    "        y_pred = model(x_batch)\n",
    "        loss = F.cross_entropy(y_pred, y_batch) #внутри сам считает softma[ ]\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if num_step %10000 == 0:\n",
    "            print(loss.item())\n",
    "        \n",
    "    model.eval()\n",
    "    score = test(model, test_df)\n",
    "    print(epoch, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "num_epoch = 10\n",
    "p = 0.15\n",
    "\n",
    "dl = DataLoader(ds, batch_size = 8, shuffle = True, collate_fn = collate_fn)\n",
    "model = MLMTransformer(vocab_size = len(vocab),\n",
    "                                  d = 32, n_head = 4, d_hid = 64, \n",
    "                                  n_blocks = 2\n",
    "                                 )\n",
    "opt = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    for num_step, (x_batch, y_batch) in tqdm(enumerate(dl)):\n",
    "        opt.zero_grad()\n",
    "        x_batch = x_batch['x']\n",
    "        # 1-сгенерировать маску с размерностью как ч батча\n",
    "        mask = torch.rand(x_batch.shape) < p\n",
    "        # 2-меняем вход для модели\n",
    "        x_batch_ = x_batch.clone()\n",
    "        x_batch[mask] = vocab.MASK\n",
    "        # 3-надо скопировать батч чтобы использовать как y в loss\n",
    "        y_pred = model(x_batch)\n",
    "        loss = F.cross_entropy(y_pred.transpose(1,2), x_batch, reduction='none' ) #внутри сам считает softma[ ]\n",
    "        loss = (loss * mask.float()).sum()/mask.sum()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if num_step %100 == 0:\n",
    "            print(loss.item())\n",
    "        \n",
    "    model.eval()\n",
    "    score = test(model, test_df)\n",
    "    print(epoch, score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
