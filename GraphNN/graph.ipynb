{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9Y68DtQ4DU3"
   },
   "source": [
    " # Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rkKjPmIRQ4Ne"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv,MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roW8_FdA4IKU"
   },
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "SYXNIpX08BVx",
    "outputId": "ba56511a-659f-4916-beca-cbd2247b4bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([86476])\n",
      "torch.Size([2, 246220])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "data = pd.read_csv('vk_friends.csv')\n",
    "\n",
    "source = data['Source'].to_numpy()\n",
    "target = data['Target'].to_numpy()\n",
    "\n",
    "source = torch.from_numpy(source)\n",
    "#source =torch.where(source >=10000000,random.randint(0,10000000),source) \n",
    "target = torch.from_numpy(target)\n",
    "#target =torch.where(target >=10000000,random.randint(0,10000000),target) \n",
    "\n",
    "edge_index = torch.stack([source,target],dim = 0)\n",
    "vertex = torch.cat([source,target],dim=-1)\n",
    "\n",
    "x = torch.unique(vertex)\n",
    "print(x.shape)\n",
    "node2id = {x[i].item():i for i in range(x.shape[0])}\n",
    "\n",
    "new_x = torch.tensor([[v] for v in node2id.values()], dtype = torch.float)\n",
    "\n",
    "new_edge_index = torch.tensor([[node2id[edge_index[0][i].item()] for i in range(edge_index.shape[1])],[node2id[edge_index[1][i].item()] for i in range(edge_index.shape[1])]])\n",
    "print(new_edge_index.shape)\n",
    "data = Data(x=new_x, edge_index=new_edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7-mPt5bHVYS",
    "outputId": "cdc57084-6165-48ef-8137-c7eee04e8764"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4766,   228,   228,  ..., 65045, 65045,  4766],\n",
       "        [  228,     1,     2,  ..., 44892, 44892, 65222]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqEkKXtN3sV1"
   },
   "source": [
    "# Splitting dataset to train/test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4oZb6tLyuMuu"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "TRAIN_BATCH_SIZE = 1000\n",
    "TEST_BATCH_SIZE = 1000\n",
    "\n",
    "train_dataset, test_dataset = random_split(data.x,[70000,16476])\n",
    "\n",
    "train_edges, test_edges = random_split(data.edge_index.T,[190000,56220])\n",
    "\n",
    "train_data = Data(x=train_dataset.dataset, edge_index=train_edges.dataset.T)\n",
    "test_data = Data(x=test_dataset.dataset, edge_index=test_edges.dataset.T)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(range(train_data.edge_index.shape[1]),\n",
    "                          batch_size = TRAIN_BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(range(test_data.edge_index.shape[1]),\n",
    "                         batch_size = TEST_BATCH_SIZE, \n",
    "                         shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQW91LlK4LaA"
   },
   "source": [
    "# GraphSage model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UFmHA1OqCBgj"
   },
   "outputs": [],
   "source": [
    "class GraphSage(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, normalize=True,\n",
    "                 bias=False, **kwargs):\n",
    "        super(GraphSage, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.lin_l = torch.nn.Linear(in_channels, out_channels, bias=bias)\n",
    "        self.lin_r = torch.nn.Linear(in_channels, out_channels, bias=bias)\n",
    "\n",
    "    def forward(self, x, edge_index, size=None):\n",
    "        neighbor_out = self.propagate(edge_index, x=(x, x), size=size)\n",
    "        out = self.lin_l(x) + self.lin_r(neighbor_out)\n",
    "        if self.normalize:\n",
    "            out = torch.nn.functional.normalize(out, p=2)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVeDIZDM4OOJ"
   },
   "source": [
    "# Link Predictor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GIaMuUH4jQsA"
   },
   "outputs": [],
   "source": [
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout =0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lins = nn.ModuleList()\n",
    "        self.lins.append(nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j # scalar-product for tensors\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x)\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPzfOIjT4RhK"
   },
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Zbuagb_QGdpO"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 3\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "model = GraphSage(in_channels = 1,\n",
    "                  out_channels = 64)                    \n",
    "\n",
    "link_predictor = LinkPredictor(in_channels= 64,\n",
    "                               hidden_channels = 128,\n",
    "                               out_channels = 2,\n",
    "                               num_layers = 4)\n",
    "  \n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), link_predictor.parameters()),\n",
    "                             lr = 0.001,\n",
    "                             weight_decay = 0.001)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer = optimizer,\n",
    "                                               step_size = 1,\n",
    "                                               gamma = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIS7bp-AjRit",
    "outputId": "cfa9f37f-ead4-495d-a8b7-5a2a7e7bf81f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1/Iteration 11 : 1.3855202198028564\n",
      " Epoch 1/Iteration 21 : 1.3813390731811523\n",
      " Epoch 1/Iteration 31 : 1.364211916923523\n",
      " Epoch 1/Iteration 41 : 1.2927398681640625\n",
      " Epoch 1/Iteration 51 : 1.0750616788864136\n",
      " Epoch 1/Iteration 61 : 0.8088548183441162\n",
      " Epoch 1/Iteration 71 : 0.729498028755188\n",
      " Epoch 1/Iteration 81 : 0.7088220119476318\n",
      " Epoch 1/Iteration 91 : 0.6813292503356934\n",
      " Epoch 1/Iteration 101 : 0.6076738834381104\n",
      " Epoch 1/Iteration 111 : 0.6456466913223267\n",
      " Epoch 1/Iteration 121 : 0.6809768676757812\n",
      " Epoch 1/Iteration 131 : 0.6309910416603088\n",
      " Epoch 1/Iteration 141 : 0.6701458692550659\n",
      " Epoch 1/Iteration 151 : 0.5998407602310181\n",
      " Epoch 1/Iteration 161 : 0.6271449327468872\n",
      " Epoch 1/Iteration 171 : 0.6266093254089355\n",
      " Epoch 1/Iteration 181 : 0.6082190275192261\n",
      " Epoch 1/Iteration 191 : 0.6540667414665222\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b7c500574836>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mpos_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_emb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos_edge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_emb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos_edge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         neg_edge = negative_sampling(data.edge_index, \n\u001b[0m\u001b[0;32m     19\u001b[0m                                      \u001b[0mnum_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                                      \u001b[0mnum_neg_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medge_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\utils\\negative_sampling.py\u001b[0m in \u001b[0;36mnegative_sampling\u001b[1;34m(edge_index, num_nodes, num_neg_samples, method, force_undirected)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# The dense version creates a mask of shape `population` to check for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;31m# invalid samples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_ones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Number of tries to sample negative indices.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_loss = np.inf\n",
    "\n",
    "model.to(device)\n",
    "link_predictor.to(device)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):    \n",
    "    model.train()\n",
    "    link_predictor.train()\n",
    "\n",
    "    iteration = 1\n",
    "    for edge_id in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        node_emb = model(train_data.x.to(device), train_data.edge_index.to(device))  \n",
    "        \n",
    "        pos_edge = train_data.edge_index[:,edge_id]\n",
    "        pos_pred = link_predictor(node_emb[pos_edge[0]].to(device), node_emb[pos_edge[1]].to(device)) \n",
    "        \n",
    "        neg_edge = negative_sampling(data.edge_index, \n",
    "                                     num_nodes=train_data.x.shape[0],\n",
    "                                     num_neg_samples=edge_id.shape[0],\n",
    "                                     method='dense')\n",
    "        \n",
    "        neg_pred = link_predictor(node_emb[neg_edge[0]].to(device), node_emb[neg_edge[1]].to(device))\n",
    "       \n",
    "        loss = -torch.log(pos_pred + 1e-15).mean() -  torch.log(1 - neg_pred + 1e-15).mean()\n",
    "        loss.backward()\n",
    "       \n",
    "        optimizer.step()\n",
    "        \n",
    "        if iteration % 10 == 0 :\n",
    "            print(f' Epoch {epoch+1}/Iteration {iteration+1} : {loss.item()}')\n",
    "        iteration+=1\n",
    "\n",
    "        if min_loss > loss.item():\n",
    "            min_loss = loss.item()\n",
    "            torch.save(model.state_dict(), 'model.pth')\n",
    "            torch.save(link_predictor.state_dict(), 'predictor.pth')\n",
    "\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL64ayi5FYxN"
   },
   "source": [
    "# Loading pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FapCbW7FEg0",
    "outputId": "58dff6ed-7784-4820-e0a1-4adca097fb7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraphSage(in_channels = 1,\n",
    "                      out_channels = 64)                    \n",
    "\n",
    "predictor = LinkPredictor(in_channels= 64,\n",
    "                                   hidden_channels = 128,\n",
    "                                   out_channels = 2,\n",
    "                                   num_layers = 4)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "predictor.load_state_dict(torch.load('predictor.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k5rtvz5GVnn"
   },
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "xpOyaVDPGTxH"
   },
   "outputs": [],
   "source": [
    "def test(model, predictor):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    node_emb = model(test_data.x, test_data.edge_index)\n",
    "\n",
    "    pos_edges = test_data.edge_index\n",
    "    neg_edges = negative_sampling(test_data.edge_index, \n",
    "                                     num_nodes=test_data.x.shape[0],\n",
    "                                     num_neg_samples=int(test_data.edge_index.shape[1]*0.3),\n",
    "                                     method='dense')\n",
    "    pos_test_preds = []\n",
    "\n",
    "    for edge_id in test_loader:  \n",
    "        edge = pos_edges[:,edge_id]\n",
    "        pos_test_preds += [predictor(node_emb[edge[0]], node_emb[edge[1]])]\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "    \n",
    "    pos_preds = [1 if torch.sum(i)/2 >=0.7 else 0 for i in pos_test_pred.detach()] \n",
    "    \n",
    "    neg_test_preds = []\n",
    "    for edge_id in DataLoader(range(neg_edges.shape[1]),\n",
    "                         batch_size = TEST_BATCH_SIZE, \n",
    "                         shuffle=True):\n",
    "        edge = neg_edges[:,edge_id]\n",
    "        neg_test_preds += [predictor(node_emb[edge[0]], node_emb[edge[1]])]\n",
    "        \n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "\n",
    "    neg_preds = [1 if torch.sum(i)/2 >=0.7  else 0  for i in neg_test_pred.detach()] \n",
    "\n",
    "    pos_preds = np.array(pos_preds)\n",
    "    neg_preds = np.array(neg_preds)\n",
    "    \n",
    "    check = np.hstack((np.ones(pos_preds.shape[0]),np.zeros(neg_preds.shape[0])))\n",
    "    \n",
    "    preds = np.hstack((pos_preds,neg_preds))\n",
    "    score = f1_score(check, preds)\n",
    "    \n",
    "    print(f'Score : {score}')\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mIayqpDWiW1P",
    "outputId": "b1154329-7302-45da-9f19-f2f2f634507c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.8917772524874938\n"
     ]
    }
   ],
   "source": [
    "test(model,predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUUjyvpR67xr"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "bFBfIw2i6-ti"
   },
   "outputs": [],
   "source": [
    "def predict(node_1,node_2,threshhold = 0.7,model,predictor):\n",
    "    node_1 = node2id[node_1]\n",
    "    node_2 = node2id[node_2]\n",
    "    \n",
    "    node_emb = model(data.x,data.edge_index)\n",
    "\n",
    "    pred = predictor(node_emb[node_1], node_emb[node_2]) \n",
    "    \n",
    "    if torch.sum(pred)/2 >= threshhold:\n",
    "         print('Nodes - connected')\n",
    "    else:\n",
    "         print('Nodes - are NOT connected')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PaeOZqVAPGy",
    "outputId": "b45af201-434a-49bd-b68c-59a005ba639f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes - connected\n"
     ]
    }
   ],
   "source": [
    "predict(99210,3520,0.7,model,predictor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
